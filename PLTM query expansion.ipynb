{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"data/sequence/\")\n",
    "num_language=2\n",
    "fold_num  =0\n",
    "with open(\"pltm_output_topics{}.txt\".format(fold_num)) as f : \n",
    "    lines = f.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_highe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Process the MALLET output into a list of list of top topic words \n",
    "herb_top_topic_words =[]\n",
    "sympt_top_topic_words =[]\n",
    "for l in lines: \n",
    "    ls =l.split('\\t')\n",
    "    if len(ls) ==2:\n",
    "        #Beginning of a new topic\n",
    "        pass\n",
    "    else:\n",
    "#         print ls[0]\n",
    "#         print ls[3]\n",
    "        word_lst = ls[3].split(\" \")\n",
    "        if int(ls[0])==0:\n",
    "            #HERB language\n",
    "            herb_top_topic_words.append(word_lst)\n",
    "        elif int(ls[0])==1:\n",
    "            #SYMPT language\n",
    "            sympt_top_topic_words.append(word_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Query expansion based on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mkdir ../../results/bilda_word_distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "run_num=0\n",
    "lda_type='bilda'\n",
    "\n",
    "# code_list = read_code_list(run_num)\n",
    "# word_distr = np.loadtxt('./results/%s_word_distributions/'\n",
    "#     '%s_word_distribution_%d.txt' % (lda_type, lda_type, run_num))\n",
    "\n",
    "out = open('./data/train_test/test_lda_expansion_%d.txt' % run_num, 'w')\n",
    "f = open('./data/train_test/test_no_expansion_%d.txt' % run_num, 'r')\n",
    "for query in f:\n",
    "    # Split by tab, fifth element, split by comma, take out trailing comma.\n",
    "    query = query.split('\\t')\n",
    "    symptom_list = query[4].split(':')[:-1]\n",
    "\n",
    "#     expansion_terms = get_highest_prob_words(symptom_list, scaled_topic)\n",
    "\n",
    "#     # Write expanded query to file\n",
    "#     expanded_query = query[:]\n",
    "#     expanded_query[4] += ':'.join(expansion_terms) + ':'\n",
    "\n",
    "#     out.write('\\t'.join(expanded_query))\n",
    "# f.close()\n",
    "# out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe8\\x88\\x8c\\xe5\\xb9\\xb2\\xe6\\xb6\\xa9',\n",
       " '\\xe8\\x83\\x83\\xe8\\x84\\x98\\xe7\\x95\\x8f\\xe5\\xaf\\x92\\xe6\\x98\\x8e\\xe6\\x98\\xbe\\xe5\\xa5\\xbd\\xe8\\xbd\\xac',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe7\\xba\\xa2\\xe8\\x83\\x96',\n",
       " '\\xe5\\x8f\\xa3\\xe8\\x87\\xad',\n",
       " '\\xe8\\x88\\x8c\\xe7\\x81\\xbc\\xe7\\x83\\xad\\xe6\\x84\\x9f',\n",
       " '\\xe5\\xa4\\xa7\\xe4\\xbe\\xbf\\xe5\\x81\\x8f\\xe5\\xb9\\xb2',\n",
       " '\\xe5\\x97\\xb3\\xe6\\xb0\\x94\\xe5\\xa5\\xbd\\xe8\\xbd\\xac',\n",
       " '\\xe8\\x84\\x89\\xe6\\xb2\\x89\\xe7\\xbb\\x86',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9c\\xa8']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "symptom_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compute co-occurence\n",
    "cooccurence =[filter(lambda x: x in symptom_list, topic_lst) for topic_lst in sympt_top_topic_words]\n",
    "cooccurence_count = [len(c) for c in cooccurence] #cooccurence count for each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cooccurence_count\n",
    "np.array(cooccurence_count)[np.argsort(cooccurence_count)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_symptom = len(symptom_list)\n",
    "#top-k cooccurence topics index\n",
    "topk_topics  = np.argsort(cooccurence_count)[::-1][:3*num_symptom+1]\n",
    "#find query expansion terms by looking at top-occuring words in those topics \n",
    "topk_sympt_top_topic_words = np.array(sympt_top_topic_words)[topk_topics]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "2*num_symptom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topk_sympt_top_topic_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "flatten_lst = []\n",
    "for word_lst in topk_sympt_top_topic_words:\n",
    "    flatten_lst+=word_lst\n",
    "import collections\n",
    "word_counter = collections.Counter(flatten_lst)\n",
    "expansion_terms = []\n",
    "for k,v in word_counter.most_common(2*num_symptom+1):\n",
    "    if k!='\\n':\n",
    "        expansion_terms.append(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe8\\x84\\x89\\xe6\\xb2\\x89\\xe7\\xbb\\x86',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe7\\xba\\xa2\\xe8\\x83\\x96',\n",
       " '\\xe4\\xb9\\x8f\\xe5\\x8a\\x9b',\n",
       " '\\xe5\\x8f\\xa3\\xe8\\x87\\xad',\n",
       " '\\xe5\\x8f\\xa3\\xe8\\x8b\\xa6',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9c\\x89\\xe8\\xa3\\x82\\xe7\\xba\\xb9',\n",
       " '\\xe8\\x84\\x89\\xe6\\xb2\\x89\\xe7\\xbb\\x86\\xe5\\xbc\\xa6',\n",
       " '\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0\\xe5\\xb7\\xae',\n",
       " '\\xe5\\xa4\\xa7\\xe4\\xbe\\xbf\\xe5\\x81\\x8f\\xe5\\xb9\\xb2',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe7\\xba\\xa2',\n",
       " '\\xe5\\xa4\\x9c\\xe9\\x97\\xb4\\xe5\\x8f\\xa3\\xe5\\xb9\\xb2',\n",
       " '\\xe8\\x88\\x8c\\xe7\\xba\\xa2',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe8\\x83\\x96',\n",
       " '\\xe8\\x8b\\x94\\xe8\\x96\\x84\\xe9\\xbb\\x84',\n",
       " '\\xe8\\x88\\x8c\\xe7\\xb4\\xab\\xe6\\x9a\\x97',\n",
       " '\\xe8\\x8b\\x94\\xe9\\xbb\\x84',\n",
       " '\\xe4\\xb8\\x8a\\xe8\\x85\\xb9\\xe9\\x83\\xa8']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "expansion_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/dorislee/Desktop/Fall2016/Research/tcm/tcm-biLDA\n"
     ]
    }
   ],
   "source": [
    "cd ../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_highest_cooccuring_words(symptom_list,run_num):\n",
    "    with open(\"./data/sequence/pltm_output_topics{}.txt\".format(run_num)) as f : \n",
    "        lines = f.readlines()\n",
    "        #Process the MALLET output into a list of list of top topic words \n",
    "        herb_top_topic_words =[]\n",
    "        sympt_top_topic_words =[]\n",
    "        for l in lines: \n",
    "            ls =l.split('\\t')\n",
    "            if len(ls) ==2:\n",
    "                #Beginning of a new topic\n",
    "                pass\n",
    "            else:\n",
    "        #         print ls[0]\n",
    "        #         print ls[3]\n",
    "                word_lst = ls[3].split(\" \")\n",
    "                if int(ls[0])==0:\n",
    "                    #HERB language\n",
    "                    herb_top_topic_words.append(word_lst)\n",
    "                elif int(ls[0])==1:\n",
    "                    #SYMPT language\n",
    "                    sympt_top_topic_words.append(word_lst)\n",
    "    #Compute co-occurence\n",
    "    cooccurence =[filter(lambda x: x in symptom_list, topic_lst) for topic_lst in sympt_top_topic_words]\n",
    "    cooccurence_count = [len(c) for c in cooccurence] #cooccurence count for each topic \n",
    "    num_symptom = len(symptom_list)\n",
    "    #top-k cooccurence topics index\n",
    "    topk_topics  = np.argsort(cooccurence_count)[::-1][:3*num_symptom+1]\n",
    "    #find query expansion terms by looking at top-occuring words in those topics \n",
    "    topk_sympt_top_topic_words = np.array(sympt_top_topic_words)[topk_topics]\n",
    "\n",
    "    flatten_lst = []\n",
    "    for word_lst in topk_sympt_top_topic_words:\n",
    "        flatten_lst+=word_lst\n",
    "\n",
    "    word_counter = collections.Counter(flatten_lst)\n",
    "    expansion_terms = []\n",
    "    for k,v in word_counter.most_common(2*num_symptom+1):\n",
    "        if k!='\\n':\n",
    "            expansion_terms.append(k)\n",
    "    return expansion_terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\\xe8\\x84\\x89\\xe6\\xb2\\x89\\xe7\\xbb\\x86',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe7\\xba\\xa2\\xe8\\x83\\x96',\n",
       " '\\xe4\\xb9\\x8f\\xe5\\x8a\\x9b',\n",
       " '\\xe5\\x8f\\xa3\\xe8\\x87\\xad',\n",
       " '\\xe5\\x8f\\xa3\\xe8\\x8b\\xa6',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9c\\x89\\xe8\\xa3\\x82\\xe7\\xba\\xb9',\n",
       " '\\xe8\\x84\\x89\\xe6\\xb2\\x89\\xe7\\xbb\\x86\\xe5\\xbc\\xa6',\n",
       " '\\xe7\\x9d\\xa1\\xe7\\x9c\\xa0\\xe5\\xb7\\xae',\n",
       " '\\xe5\\xa4\\xa7\\xe4\\xbe\\xbf\\xe5\\x81\\x8f\\xe5\\xb9\\xb2',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe7\\xba\\xa2',\n",
       " '\\xe5\\xa4\\x9c\\xe9\\x97\\xb4\\xe5\\x8f\\xa3\\xe5\\xb9\\xb2',\n",
       " '\\xe8\\x88\\x8c\\xe7\\xba\\xa2',\n",
       " '\\xe8\\x88\\x8c\\xe6\\x9a\\x97\\xe8\\x83\\x96',\n",
       " '\\xe8\\x8b\\x94\\xe8\\x96\\x84\\xe9\\xbb\\x84',\n",
       " '\\xe8\\x88\\x8c\\xe7\\xb4\\xab\\xe6\\x9a\\x97',\n",
       " '\\xe8\\x8b\\x94\\xe9\\xbb\\x84',\n",
       " '\\xe4\\xb8\\x8a\\xe8\\x85\\xb9\\xe9\\x83\\xa8']"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_highest_cooccuring_words(symptom_list,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
